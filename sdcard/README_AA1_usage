/******************************************************************************
* Copyright (C) 2010 - 2020 Xilinx, Inc. All rights reserved.
* SPDX-License-Identifier: Apache-2.0
******************************************************************************/
The following file outlines the file structure and instructions on how to use
the AA1 application. This file outlines the HW requirements for the application,
how to run the application, and an overview of the application file structure. 

1. How to run the example application:
    A) Hardware and software set-up:
       a) Monitor:
          Before booting, connect the monitor to the board via either DP or HDMI port.
       b) IAS sensor:
          Before power on, install a AR1335 sensor module in J7.
       c) UART/JTAG interface:
          For interacting and seeing boot time information connect a USB debugger to the J4.
       d) You may also use a USB webcam as an input device. 
           The webcam is optional video input device supported in the application.
           Recommended is the Logitech BRIO.
       d) Network connection:
          Connect the Ethernet cable to your local network with DHCP enabled or a direct PC connection
          with a static IP configuration.
       e) RTSP client:
          You will use a PC having network access to the board as the RTSP client machine.
          On the client machine, to receive and play the RTSP stream, you need to install ffplay which is part of package FFmpeg.
            For Linux, you can install FFmpeg with the package manager of your distribution.
            For Windows, you can find install instructions on https://ffmpeg.org/download.html

    B) Two methods of interacting with the application are provided. 
       a) A Juypter notebook. Use a web-browser (e.g. Chrome, Firefox) to interact with the platform.
          i) The Jupyter notebook URL will be printed to the UART if the board is connected and allocated an IP address at boot. 
                Example: http://<board_ip_addr>:8888
          ii) If using a direct connection (no DHCP) see public documentation on how to configure your PC with a static IP on the same subnet. 
              For the SOM target set the desired IP address within the same subnet using ifconfig.
                Example: ifconfig eth0 10.0.1.15 netmask 255.255.255.0
              The notebook will be available at http://<your defined IP addr>:8888
       
       b) Command line scripts and configurations. These allow for the user to define different video input and output device targets using
          the "somapp" application. These are to be executed using the UART/debug interface. Example scripts and configuration definitions 
          are provided below.

    C) Example scripts are provided on the system. For location see "File Structure"

       a) MIPI RTSP server:
         i) Invoking "01.mipi-rtsp.sh" will start rtsp server for mipi captured images
         ii) Script accepts ${width} ${height} as the 1st and 2nd parameter, the default is 1920 x 1080
         iii) Run "ffplay rtsp://boardip:5000/test" on the client PC to receive the rtsp stream.
         iv) Checking:
            You should be able to see the images the camera is capturing on the ffplay window, and when there's face captured 
            by camera, there should be blue box drawn around the face, and the box should follow the movement of the face.

       b) MIPI DP display
         i) Make sure the monitor is connected as 0)-a).
         ii) Invoking "02.mipi-dp.sh" will play the captured video with detection results on monitor.
         iii) Script accepts ${width} ${height} as the 1st and 2nd parameter, the default is 1920 x 1080
         iv) Checking:
            You should be able to see the images the camera is capturing on the monitor connected to the board,  and when there's
            face captured by camera, there should be blue box drawn around the face, and the box should follow the movement of the face.

       c) File to File
         i) Invoking "03.file-to-file.sh"
         ii) Read in the sample video file from "/usr/share/somapp/movies/walking-people.nv12.30fps.1080p.h264",
            perform detection and generate video with detection bbox, save as ./out.h264
         iii) Checking:
            Play the input video file "/usr/share/somapp/movies/walking-people.nv12.30fps.1080p.h264" and generated video file 
            "./out.h264" with any media player you prefer, e.g. VLC, ffplay.
            You should be able to see in the output video file, there are blue boxes around the faces of walking people, and the boxes
            should follow the movement of the faces, while there's no such boxes with the input video file.

2. Additional configuration options for somapp invocation:
   The example scripts and Jupyter notebook work as examples to show capability of the somapp for specific configurations.
   More combinations could be made based on the options provided by somapp.
   You can get detailed application options as following by invoking ./somapp --help.

    Usage:
      somapp [OPTION?] - Application for face detection on SOM board of Xilinx.
    
    Help Options:
      -?, --help                        Show help options
      --help-all                        Show all help options
      --help-gst                        Show GStreamer Options
    
    Application Options:
      -m, --mipi=media_ID               mipi media id, e.g. 1 for /dev/media1
      -u, --usb=video_ID                usb camera video device id, e.g. 2 for /dev/video2
      -f, --file=file path              location of h26x file as input
      -i, --infile-type=h264            input file type: [h264 | h265]
      -w, --w=1920                      resolution w of the input
      -h, --h=1080                      resolution h of the input
      -r, --framerate=30                framerate of the input
      -t, --target=dp                   [dp|rtsp|file]
      -o, --outmedia-type=h264          output file type: [h264 | h265]
      -p, --port=5000                   Port to listen on (default: 5000)
      -n, --nodet                       no AI inference

   Example of supported combinations sorted by input are outlined below. If using command line to invoke
   the somapp stop the process via CTLR-C prior to starting the next instance.
   Note some of the configurations have functional limitations in EA1.
   have limitations:
   A) input MIPI (IAS sensor input):
      output: RTSP
        somapp  --mipi 0 -w 1920 -h 1080 --target rtsp >/dev/null 2>&1
      output: DP
        somapp  --mipi 0 -w 1920 -h 1080 --target dp >/dev/null 2>&1
      output: file
        somapp  --mipi 0 -w 1920 -h 1080 --target file >/dev/null 2>&1

   B) input file (file on file system):
      output: RTSP [!Not functional in EA1]
        somapp  --file ./test.h264 -i h264 -w 1920 -h 1080 -r 30 --target rtsp >/dev/null 2>&1 
      output: DP [!Not functional in EA1]
        somapp  --file ./test.h264 -i h264 -w 1920 -h 1080 -r 30 --target dp >/dev/null 2>&1
      output: file
        somapp  --file ./test.h264 -i h264 -w 1920 -h 1080 -r 30 --target file >/dev/null 2>&1

      *Note you must update the command to the specific file desired as input source.

   C) input USB (USB webcam): [!Detection limitation with USB3.0 cameras]
      output: RTSP
        somapp  --usb 1 -w 1920 -h 1080 -r 30 --target rtsp >/dev/null 2>&1      
      output: DP
        somapp  --usb 1 -w 1920 -h 1080 -r 30 --target dp >/dev/null 2>&1
      output: file
        somapp  --usb 1 -w 1920 -h 1080 -r 30 --target file >/dev/null 2>&1
      
      *You must ensure the width/height/framerate defined are supported by your USB camera.


3. File structure:
    The application is installed as:
        Binary File: => /opt/xilinx/bin
                                        somapp                      main app

        Script File: => /opt/xilinx/bin/
                                        setupmipi.sh         find mipi media number, to be used by somapp.
                                        01.mipi-rtsp.sh      call somapp to run facedetction and send out rtsp stream.
                                        02.mipi-dp.sh        call somapp to run facedetction and display on DP display.
                                        03.file-file.sh      call somapp to run facedetction and display on input h264/5
                                                                  file and generate output h264/5 with detection boxes.
        configuration File: => /opt/xilinx/share/ivas
                                        kernel_boundingbox_facedetect.json
                                        kernel_densebox_640_360.json
                                        kernel_xpp_pipeline.json

    Jupyter notebook file:  => /usr/share/notebooks/somapp
                                        AA1.ipynb
                                                             Jupyter notebook file for MIPI->RTSP demo.

    Example video files: => /usr/share/somapp/movies
